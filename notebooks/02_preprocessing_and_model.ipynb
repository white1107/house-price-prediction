{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理とベースラインモデル構築\n",
    "## Kaggle House Prices: Advanced Regression Techniques\n",
    "\n",
    "このノートブックでは、Kaggle住宅価格予測コンペティションのデータに対して、以下のステップを実行します。\n",
    "\n",
    "1. **データの読み込み** - 訓練データとテストデータの読み込み、目的変数の対数変換\n",
    "2. **外れ値の除去** - EDAで発見した異常値を除去\n",
    "3. **欠損値の処理** - 欠損値の意味を理解し、適切に補完\n",
    "4. **特徴量エンジニアリング** - ドメイン知識を活用して新しい特徴量を作成\n",
    "5. **エンコーディング** - カテゴリカル変数を数値に変換\n",
    "6. **スケーリング** - 特徴量のスケールを統一\n",
    "7. **ベースラインモデル（Ridge回帰）** - 最初のモデルを構築\n",
    "8. **モデル比較** - 複数のモデルを比較して最適なものを選択\n",
    "9. **提出ファイル作成** - Kaggleに提出する予測ファイルを生成\n",
    "\n",
    "**学習目標**: 各ステップの「なぜ」を理解し、機械学習パイプラインの全体像を把握する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('ライブラリのインポート完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. データの読み込み\n",
    "\n",
    "### なぜ目的変数を対数変換するのか？\n",
    "\n",
    "住宅価格（`SalePrice`）は**右に歪んだ分布**（正の歪度）を持っています。つまり、安い家が多く、高い家は少ないという分布です。\n",
    "\n",
    "線形回帰をはじめとする多くのモデルは、目的変数が**正規分布に近い**ことを仮定しています。対数変換を行うことで：\n",
    "\n",
    "- 分布が正規分布に近づく\n",
    "- 極端に高い価格のデータの影響が緩和される\n",
    "- モデルの予測精度が向上する\n",
    "- Kaggleのこのコンペティションの評価指標がRMSLE（Root Mean Squared Log Error）であるため、対数変換した値に対するRMSEが評価指標と一致する\n",
    "\n",
    "`np.log1p(x)` は `np.log(1 + x)` と同じです。`1` を足すのは、値が `0` の場合に `log(0)` が `-inf` になるのを防ぐためです。\n",
    "\n",
    "### なぜ訓練データとテストデータを結合するのか？\n",
    "\n",
    "前処理（欠損値補完、エンコーディング等）を訓練データとテストデータで**一貫して**行うためです。別々に処理すると、ダミー変数のカラム数が異なるなどの問題が発生します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv('/home/rex/Documents/lb/Kaggle/house-price-prediction/data/raw/train.csv')\n",
    "test = pd.read_csv('/home/rex/Documents/lb/Kaggle/house-price-prediction/data/raw/test.csv')\n",
    "\n",
    "print(f'訓練データ: {train.shape[0]}行 × {train.shape[1]}列')\n",
    "print(f'テストデータ: {test.shape[0]}行 × {test.shape[1]}列')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数の分布を確認（対数変換前後の比較）\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 変換前\n",
    "axes[0].hist(train['SalePrice'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('SalePrice（変換前）', fontsize=14)\n",
    "axes[0].set_xlabel('SalePrice')\n",
    "axes[0].set_ylabel('頻度')\n",
    "skew_before = train['SalePrice'].skew()\n",
    "axes[0].text(0.65, 0.85, f'歪度: {skew_before:.3f}', transform=axes[0].transAxes, fontsize=12,\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# 変換後\n",
    "axes[1].hist(np.log1p(train['SalePrice']), bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('log1p(SalePrice)（変換後）', fontsize=14)\n",
    "axes[1].set_xlabel('log1p(SalePrice)')\n",
    "axes[1].set_ylabel('頻度')\n",
    "skew_after = np.log1p(train['SalePrice']).skew()\n",
    "axes[1].text(0.65, 0.85, f'歪度: {skew_after:.3f}', transform=axes[1].transAxes, fontsize=12,\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n対数変換により歪度が {skew_before:.3f} → {skew_after:.3f} に改善されました')\n",
    "print('歪度が0に近いほど正規分布に近い形状です')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数を分離して対数変換\n",
    "y_train = np.log1p(train['SalePrice'])\n",
    "\n",
    "# Idを保存（後で提出ファイルに使用）\n",
    "train_id = train['Id']\n",
    "test_id = test['Id']\n",
    "\n",
    "# 訓練データの行数を記録（後で分割に使用）\n",
    "n_train = train.shape[0]\n",
    "\n",
    "# SalePriceとIdを除いて結合\n",
    "train.drop(['SalePrice', 'Id'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "# 訓練データとテストデータを結合\n",
    "all_data = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "print(f'結合データ: {all_data.shape[0]}行 × {all_data.shape[1]}列')\n",
    "print(f'  - 訓練データ: {n_train}行（インデックス 0 〜 {n_train-1}）')\n",
    "print(f'  - テストデータ: {all_data.shape[0] - n_train}行（インデックス {n_train} 〜 {all_data.shape[0]-1}）')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 外れ値の除去\n",
    "\n",
    "### なぜ外れ値を除去するのか？\n",
    "\n",
    "EDA（探索的データ分析）で、`GrLivArea`（地上階の面積）が **4000平方フィート以上** なのに `SalePrice` が非常に低い住宅が2件見つかっています。これは明らかに異常な取引（例：親族間の格安売却など）であり、モデルの学習に悪影響を与えます。\n",
    "\n",
    "**注意**: 外れ値の除去は訓練データに対してのみ行います。テストデータの外れ値は除去できません（予測しなければならないため）。\n",
    "\n",
    "**重要**: 外れ値の除去は慎重に行う必要があります。データの分布を理解した上で、ドメイン知識に基づいて判断します。むやみに除去すると、モデルが一般化できなくなる可能性があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 外れ値を可視化\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 訓練データ部分のみプロット\n",
    "train_part = all_data.iloc[:n_train]\n",
    "ax.scatter(train_part['GrLivArea'], y_train, alpha=0.5, color='steelblue', s=20)\n",
    "\n",
    "# 外れ値をハイライト\n",
    "outlier_mask = train_part['GrLivArea'] > 4000\n",
    "ax.scatter(train_part.loc[outlier_mask, 'GrLivArea'], y_train[outlier_mask],\n",
    "           color='red', s=100, marker='x', linewidths=3, label='外れ値 (GrLivArea > 4000)')\n",
    "\n",
    "ax.set_xlabel('GrLivArea（地上階面積）', fontsize=12)\n",
    "ax.set_ylabel('log1p(SalePrice)', fontsize=12)\n",
    "ax.set_title('GrLivArea vs SalePrice - 外れ値の特定', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'外れ値の数: {outlier_mask.sum()}件')\n",
    "print(f'外れ値のインデックス: {list(train_part[outlier_mask].index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 外れ値を除去\n",
    "# 訓練データ部分でGrLivArea > 4000のインデックスを特定\n",
    "outlier_indices = all_data.iloc[:n_train][all_data.iloc[:n_train]['GrLivArea'] > 4000].index\n",
    "\n",
    "# all_dataとy_trainから外れ値を除去\n",
    "all_data = all_data.drop(outlier_indices)\n",
    "y_train = y_train.drop(outlier_indices)\n",
    "\n",
    "# インデックスをリセット\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "# 訓練データの行数を更新\n",
    "n_train = n_train - len(outlier_indices)\n",
    "\n",
    "print(f'外れ値 {len(outlier_indices)}件を除去しました')\n",
    "print(f'更新後の訓練データ: {n_train}行')\n",
    "print(f'更新後の結合データ: {all_data.shape[0]}行')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 欠損値の処理\n",
    "\n",
    "### 欠損値処理が重要な理由\n",
    "\n",
    "多くの機械学習アルゴリズムは欠損値（NaN）を扱えません。そのため、学習前に欠損値を適切に処理する必要があります。\n",
    "\n",
    "### 欠損値の種類と処理方針\n",
    "\n",
    "この住宅データでは、欠損値には**2つの意味**があります：\n",
    "\n",
    "1. **「その設備がない」ことを意味するNA**: 例えば `PoolQC`（プール品質）がNAの場合、「プールがない」ことを意味します。この場合、カテゴリカル変数は `\"None\"`、数値変数は `0` で埋めるのが適切です。\n",
    "\n",
    "2. **本当にデータが不明なNA**: 例えば `LotFrontage`（道路接面距離）のNAは、データが記録されていないだけです。この場合、統計量（中央値やモード）で補完します。\n",
    "\n",
    "### なぜ中央値（median）を使うのか？\n",
    "\n",
    "平均値は外れ値の影響を受けやすいですが、中央値は**ロバスト**（外れ値に強い）です。住宅データには極端な値が含まれることが多いため、中央値が安全な選択です。\n",
    "\n",
    "### LotFrontageをNeighborhoodごとの中央値で埋める理由\n",
    "\n",
    "同じ地域（Neighborhood）の住宅は似たような区画サイズを持つ傾向があります。全体の中央値よりも、地域ごとの中央値の方が正確な推定値になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の状況を確認\n",
    "missing = all_data.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "\n",
    "print(f'欠損値を持つ特徴量の数: {len(missing)}')\n",
    "print('\\n--- 欠損値の一覧（処理前） ---')\n",
    "missing_df = pd.DataFrame({\n",
    "    '欠損数': missing,\n",
    "    '欠損率(%)': (missing / len(all_data) * 100).round(2)\n",
    "})\n",
    "print(missing_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の可視化\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "missing_pct = (missing / len(all_data) * 100)\n",
    "colors = ['#d32f2f' if x > 50 else '#ff9800' if x > 10 else '#4caf50' for x in missing_pct.values]\n",
    "bars = ax.barh(range(len(missing_pct)), missing_pct.values, color=colors, edgecolor='black', alpha=0.8)\n",
    "ax.set_yticks(range(len(missing_pct)))\n",
    "ax.set_yticklabels(missing_pct.index, fontsize=9)\n",
    "ax.set_xlabel('欠損率 (%)', fontsize=12)\n",
    "ax.set_title('特徴量ごとの欠損率（処理前）', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# 凡例\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#d32f2f', edgecolor='black', label='50%超'),\n",
    "    Patch(facecolor='#ff9800', edgecolor='black', label='10-50%'),\n",
    "    Patch(facecolor='#4caf50', edgecolor='black', label='10%未満')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ステップ1: NAが「その設備がない」を意味する特徴量\n",
    "# ============================================================\n",
    "\n",
    "# --- カテゴリカル変数: \"None\" で埋める ---\n",
    "# これらの特徴量では、NAは「その設備/機能が存在しない」ことを意味する\n",
    "none_cols_cat = [\n",
    "    'PoolQC',        # プール品質 → プールなし\n",
    "    'MiscFeature',   # その他設備 → 特殊設備なし\n",
    "    'Alley',         # 路地のタイプ → 路地なし\n",
    "    'Fence',         # フェンス品質 → フェンスなし\n",
    "    'FireplaceQu',   # 暖炉品質 → 暖炉なし\n",
    "    'GarageType',    # ガレージタイプ → ガレージなし\n",
    "    'GarageFinish',  # ガレージ内装 → ガレージなし\n",
    "    'GarageQual',    # ガレージ品質 → ガレージなし\n",
    "    'GarageCond',    # ガレージ状態 → ガレージなし\n",
    "    'BsmtQual',      # 地下室品質 → 地下室なし\n",
    "    'BsmtCond',      # 地下室状態 → 地下室なし\n",
    "    'BsmtExposure',  # 地下室露出 → 地下室なし\n",
    "    'BsmtFinType1',  # 地下室仕上げ1 → 地下室なし\n",
    "    'BsmtFinType2',  # 地下室仕上げ2 → 地下室なし\n",
    "    'MasVnrType',    # 石材外装タイプ → 石材外装なし\n",
    "]\n",
    "\n",
    "for col in none_cols_cat:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "    \n",
    "print(f'カテゴリカル変数 {len(none_cols_cat)}列を \"None\" で補完しました')\n",
    "\n",
    "# --- 数値変数: 0 で埋める ---\n",
    "# ガレージや地下室がない場合、関連する数値は0\n",
    "none_cols_num = [\n",
    "    'GarageYrBlt',   # ガレージ建築年 → ガレージなし\n",
    "    'GarageArea',    # ガレージ面積 → 0\n",
    "    'GarageCars',    # ガレージ車台数 → 0\n",
    "    'BsmtFinSF1',    # 地下室仕上げ面積1 → 0\n",
    "    'BsmtFinSF2',    # 地下室仕上げ面積2 → 0\n",
    "    'BsmtUnfSF',     # 地下室未仕上げ面積 → 0\n",
    "    'TotalBsmtSF',   # 地下室総面積 → 0\n",
    "    'BsmtFullBath',  # 地下室フルバス → 0\n",
    "    'BsmtHalfBath',  # 地下室ハーフバス → 0\n",
    "    'MasVnrArea',    # 石材外装面積 → 0\n",
    "]\n",
    "\n",
    "for col in none_cols_num:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "print(f'数値変数 {len(none_cols_num)}列を 0 で補完しました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ステップ2: LotFrontage - Neighborhoodごとの中央値で補完\n",
    "# ============================================================\n",
    "\n",
    "# 各Neighborhoodの中央値を計算\n",
    "lot_frontage_by_neighborhood = all_data.groupby('Neighborhood')['LotFrontage'].median()\n",
    "\n",
    "print('Neighborhoodごとの LotFrontage 中央値（一部表示）:')\n",
    "print(lot_frontage_by_neighborhood.head(10))\n",
    "\n",
    "# Neighborhoodごとの中央値で補完\n",
    "missing_lotfrontage = all_data['LotFrontage'].isnull().sum()\n",
    "all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "print(f'\\nLotFrontage: {missing_lotfrontage}件の欠損値をNeighborhoodごとの中央値で補完しました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ステップ3: 残りの欠損値を処理\n",
    "# ============================================================\n",
    "\n",
    "# 残りの欠損値を確認\n",
    "remaining_missing = all_data.isnull().sum()\n",
    "remaining_missing = remaining_missing[remaining_missing > 0].sort_values(ascending=False)\n",
    "print('残りの欠損値:')\n",
    "print(remaining_missing)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリカル変数: 最頻値（モード）で補完\n",
    "# 理由: カテゴリカル変数の「平均」は意味がないため、最も多いカテゴリで埋める\n",
    "remaining_cat = all_data.select_dtypes(include='object').columns\n",
    "cat_filled_count = 0\n",
    "for col in remaining_cat:\n",
    "    if all_data[col].isnull().sum() > 0:\n",
    "        mode_val = all_data[col].mode()[0]\n",
    "        n_missing = all_data[col].isnull().sum()\n",
    "        all_data[col] = all_data[col].fillna(mode_val)\n",
    "        cat_filled_count += 1\n",
    "        print(f'  {col}: {n_missing}件 → 最頻値 \"{mode_val}\" で補完')\n",
    "\n",
    "print(f'\\nカテゴリカル変数 {cat_filled_count}列を最頻値で補完しました')\n",
    "\n",
    "# 数値変数: 中央値で補完\n",
    "remaining_num = all_data.select_dtypes(include=[np.number]).columns\n",
    "num_filled_count = 0\n",
    "for col in remaining_num:\n",
    "    if all_data[col].isnull().sum() > 0:\n",
    "        median_val = all_data[col].median()\n",
    "        n_missing = all_data[col].isnull().sum()\n",
    "        all_data[col] = all_data[col].fillna(median_val)\n",
    "        num_filled_count += 1\n",
    "        print(f'  {col}: {n_missing}件 → 中央値 {median_val} で補完')\n",
    "\n",
    "print(f'\\n数値変数 {num_filled_count}列を中央値で補完しました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終確認: 欠損値が残っていないことを確認\n",
    "total_missing = all_data.isnull().sum().sum()\n",
    "print(f'\\n=== 欠損値処理完了 ===')\n",
    "print(f'残りの欠損値の総数: {total_missing}')\n",
    "\n",
    "if total_missing == 0:\n",
    "    print('全ての欠損値が正常に処理されました！')\n",
    "else:\n",
    "    print('警告: まだ欠損値が残っています')\n",
    "    print(all_data.isnull().sum()[all_data.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 特徴量エンジニアリング\n",
    "\n",
    "### 特徴量エンジニアリングとは？\n",
    "\n",
    "既存のデータから**新しい特徴量**を作成することで、モデルが住宅価格をより正確に予測できるようにします。ドメイン知識（住宅市場の知識）を活用して、価格に影響する要因を明示的に表現します。\n",
    "\n",
    "### なぜ新しい特徴量を作るのか？\n",
    "\n",
    "機械学習モデルは、与えられた特徴量から**パターン**を学習します。重要な情報が明示的に特徴量として存在する方が、モデルはより効果的に学習できます。\n",
    "\n",
    "例えば「総面積」は1階・2階・地下室の面積の合計ですが、モデルがこの合計の概念を自動的に学習するのは難しい（特に線形モデルの場合）ため、明示的に作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 新しい特徴量の作成\n",
    "# ============================================================\n",
    "\n",
    "# --- TotalSF: 総面積 ---\n",
    "# 直感: 住宅の総面積は価格の最も重要な決定要因の一つ。\n",
    "# 地下室 + 1階 + 2階を合計することで、住宅全体の広さを表現。\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "print('TotalSF = TotalBsmtSF + 1stFlrSF + 2ndFlrSF')\n",
    "print(f'  範囲: {all_data[\"TotalSF\"].min():.0f} 〜 {all_data[\"TotalSF\"].max():.0f}')\n",
    "\n",
    "# --- TotalBathrooms: バスルーム合計 ---\n",
    "# 直感: バスルーム数は住宅の快適性を表す。\n",
    "# ハーフバス（洗面台+トイレのみ）はフルバスの半分の価値として計算。\n",
    "all_data['TotalBathrooms'] = (\n",
    "    all_data['FullBath'] + \n",
    "    0.5 * all_data['HalfBath'] + \n",
    "    all_data['BsmtFullBath'] + \n",
    "    0.5 * all_data['BsmtHalfBath']\n",
    ")\n",
    "print('\\nTotalBathrooms = FullBath + 0.5*HalfBath + BsmtFullBath + 0.5*BsmtHalfBath')\n",
    "print(f'  範囲: {all_data[\"TotalBathrooms\"].min():.1f} 〜 {all_data[\"TotalBathrooms\"].max():.1f}')\n",
    "\n",
    "# --- TotalPorchSF: ポーチ総面積 ---\n",
    "# 直感: ポーチ（玄関先の屋根付きスペース）の総面積。\n",
    "# アウトドアリビングスペースとして住宅の魅力を高める。\n",
    "all_data['TotalPorchSF'] = (\n",
    "    all_data['OpenPorchSF'] + \n",
    "    all_data['EnclosedPorch'] + \n",
    "    all_data['3SsnPorch'] + \n",
    "    all_data['ScreenPorch']\n",
    ")\n",
    "print('\\nTotalPorchSF = OpenPorchSF + EnclosedPorch + 3SsnPorch + ScreenPorch')\n",
    "print(f'  範囲: {all_data[\"TotalPorchSF\"].min():.0f} 〜 {all_data[\"TotalPorchSF\"].max():.0f}')\n",
    "\n",
    "# --- バイナリフラグ（有/無の特徴量） ---\n",
    "# 直感: 設備の「有無」自体が価格に大きく影響することがある。\n",
    "# 例: プールがある家は少数派であり、その存在自体が価値を持つ。\n",
    "all_data['HasPool'] = (all_data['PoolArea'] > 0).astype(int)\n",
    "all_data['HasGarage'] = (all_data['GarageArea'] > 0).astype(int)\n",
    "all_data['HasFireplace'] = (all_data['Fireplaces'] > 0).astype(int)\n",
    "print('\\nバイナリフラグ:')\n",
    "print(f'  HasPool: プールあり {all_data[\"HasPool\"].sum()}件 / {len(all_data)}件')\n",
    "print(f'  HasGarage: ガレージあり {all_data[\"HasGarage\"].sum()}件 / {len(all_data)}件')\n",
    "print(f'  HasFireplace: 暖炉あり {all_data[\"HasFireplace\"].sum()}件 / {len(all_data)}件')\n",
    "\n",
    "# --- HouseAge: 築年数 ---\n",
    "# 直感: 新しい家ほど高い傾向がある。YearBuiltよりも「何年前に建てたか」の方が直感的。\n",
    "all_data['HouseAge'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "print(f'\\nHouseAge = YrSold - YearBuilt')\n",
    "print(f'  範囲: {all_data[\"HouseAge\"].min()} 〜 {all_data[\"HouseAge\"].max()}年')\n",
    "\n",
    "# --- RemodAge: リフォームからの年数 ---\n",
    "# 直感: 最近リフォームした家は状態が良く、高く売れる傾向がある。\n",
    "all_data['RemodAge'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "print(f'\\nRemodAge = YrSold - YearRemodAdd')\n",
    "print(f'  範囲: {all_data[\"RemodAge\"].min()} 〜 {all_data[\"RemodAge\"].max()}年')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しい特徴量と目的変数の相関を確認（訓練データのみ）\n",
    "new_features = ['TotalSF', 'TotalBathrooms', 'TotalPorchSF', 'HasPool', \n",
    "                'HasGarage', 'HasFireplace', 'HouseAge', 'RemodAge']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(new_features):\n",
    "    ax = axes[i]\n",
    "    train_feat = all_data.iloc[:n_train][feat]\n",
    "    corr = np.corrcoef(train_feat, y_train)[0, 1]\n",
    "    ax.scatter(train_feat, y_train, alpha=0.3, s=10, color='steelblue')\n",
    "    ax.set_xlabel(feat, fontsize=10)\n",
    "    ax.set_ylabel('log1p(SalePrice)', fontsize=9)\n",
    "    ax.set_title(f'{feat}\\n(相関: {corr:.3f})', fontsize=11)\n",
    "\n",
    "plt.suptitle('新しい特徴量と目的変数の関係', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n各新特徴量とSalePriceの相関係数:')\n",
    "for feat in new_features:\n",
    "    corr = np.corrcoef(all_data.iloc[:n_train][feat], y_train)[0, 1]\n",
    "    print(f'  {feat:20s}: {corr:+.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. エンコーディング\n",
    "\n",
    "### なぜエンコーディングが必要なのか？\n",
    "\n",
    "機械学習モデルは**数値データ**しか扱えません。カテゴリカル変数（文字列）を数値に変換する必要があります。\n",
    "\n",
    "### 順序変数（Ordinal）と名義変数（Nominal）の違い\n",
    "\n",
    "- **順序変数（Ordinal）**: カテゴリに**自然な順序**がある変数。例: 品質（Excellent > Good > Average > Fair > Poor）。ラベルエンコーディング（数値を割り当て）が適切。\n",
    "\n",
    "- **名義変数（Nominal）**: カテゴリに**順序がない**変数。例: 屋根の材質（Gable, Hip, Flat, ...）。ワンホットエンコーディング（各カテゴリを0/1の列に展開）が適切。\n",
    "\n",
    "### なぜこの区別が重要か？\n",
    "\n",
    "名義変数にラベルエンコーディングを使うと、モデルが「数値の大小関係」を誤って学習してしまいます。例えば、地域を A=1, B=2, C=3 とエンコードすると、モデルは「CはAの3倍」のような誤った関係を学習する可能性があります。\n",
    "\n",
    "### `drop_first=True` の理由\n",
    "\n",
    "ワンホットエンコーディングで `drop_first=True` にすると、最初のカテゴリの列を削除します。これは**多重共線性**（特徴量間の完全な相関）を防ぐためです。例えば、2つのカテゴリ（A, B）がある場合、Aの列が0であればBは必ず1なので、片方の情報があれば十分です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 順序変数（Ordinal）: ラベルエンコーディング\n",
    "# ============================================================\n",
    "\n",
    "# 品質を表す順序変数のマッピング\n",
    "# Ex(Excellent)=5, Gd(Good)=4, TA(Typical/Average)=3, Fa(Fair)=2, Po(Poor)=1, None=0\n",
    "quality_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0}\n",
    "\n",
    "# 品質系の順序変数\n",
    "quality_cols = [\n",
    "    'ExterQual',     # 外装品質\n",
    "    'ExterCond',     # 外装状態\n",
    "    'BsmtQual',      # 地下室品質\n",
    "    'BsmtCond',      # 地下室状態\n",
    "    'HeatingQC',     # 暖房品質\n",
    "    'KitchenQual',   # キッチン品質\n",
    "    'FireplaceQu',   # 暖炉品質\n",
    "    'GarageQual',    # ガレージ品質\n",
    "    'GarageCond',    # ガレージ状態\n",
    "    'PoolQC',        # プール品質\n",
    "]\n",
    "\n",
    "for col in quality_cols:\n",
    "    all_data[col] = all_data[col].map(quality_mapping)\n",
    "    # マッピングに含まれない値がある場合は0で埋める\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "print('品質系の順序変数をエンコーディングしました:')\n",
    "print(f'  マッピング: {quality_mapping}')\n",
    "print(f'  対象列: {quality_cols}')\n",
    "\n",
    "# BsmtExposure: 地下室の露出度\n",
    "bsmt_exposure_mapping = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'None': 0}\n",
    "all_data['BsmtExposure'] = all_data['BsmtExposure'].map(bsmt_exposure_mapping).fillna(0)\n",
    "print(f'\\nBsmtExposure: {bsmt_exposure_mapping}')\n",
    "\n",
    "# BsmtFinType1, BsmtFinType2: 地下室仕上げタイプ\n",
    "bsmt_fin_mapping = {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'None': 0}\n",
    "for col in ['BsmtFinType1', 'BsmtFinType2']:\n",
    "    all_data[col] = all_data[col].map(bsmt_fin_mapping).fillna(0)\n",
    "print(f'BsmtFinType: {bsmt_fin_mapping}')\n",
    "\n",
    "# GarageFinish: ガレージ内装\n",
    "garage_fin_mapping = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0}\n",
    "all_data['GarageFinish'] = all_data['GarageFinish'].map(garage_fin_mapping).fillna(0)\n",
    "print(f'GarageFinish: {garage_fin_mapping}')\n",
    "\n",
    "# Fence: フェンス品質\n",
    "fence_mapping = {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'None': 0}\n",
    "all_data['Fence'] = all_data['Fence'].map(fence_mapping).fillna(0)\n",
    "print(f'Fence: {fence_mapping}')\n",
    "\n",
    "# Functional: 機能性評価\n",
    "functional_mapping = {'Typ': 7, 'Min1': 6, 'Min2': 5, 'Mod': 4, 'Maj1': 3, 'Maj2': 2, 'Sev': 1, 'Sal': 0}\n",
    "all_data['Functional'] = all_data['Functional'].map(functional_mapping).fillna(7)\n",
    "print(f'Functional: {functional_mapping}')\n",
    "\n",
    "# LandSlope: 土地の傾斜\n",
    "land_slope_mapping = {'Gtl': 2, 'Mod': 1, 'Sev': 0}\n",
    "all_data['LandSlope'] = all_data['LandSlope'].map(land_slope_mapping).fillna(2)\n",
    "print(f'LandSlope: {land_slope_mapping}')\n",
    "\n",
    "# PavedDrive: 舗装されたドライブウェイ\n",
    "paved_mapping = {'Y': 2, 'P': 1, 'N': 0}\n",
    "all_data['PavedDrive'] = all_data['PavedDrive'].map(paved_mapping).fillna(0)\n",
    "print(f'PavedDrive: {paved_mapping}')\n",
    "\n",
    "# CentralAir: セントラル空調\n",
    "all_data['CentralAir'] = all_data['CentralAir'].map({'Y': 1, 'N': 0}).fillna(0)\n",
    "print(f'CentralAir: Y=1, N=0')\n",
    "\n",
    "# Street: 道路のタイプ\n",
    "all_data['Street'] = all_data['Street'].map({'Pave': 1, 'Grvl': 0}).fillna(0)\n",
    "print(f'Street: Pave=1, Grvl=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 名義変数（Nominal）: ワンホットエンコーディング\n",
    "# ============================================================\n",
    "\n",
    "# 残りのカテゴリカル変数（object型）を確認\n",
    "remaining_cat_cols = all_data.select_dtypes(include='object').columns.tolist()\n",
    "print(f'ワンホットエンコーディング対象の名義変数: {len(remaining_cat_cols)}列')\n",
    "print(f'列名: {remaining_cat_cols}')\n",
    "\n",
    "# エンコーディング前のデータサイズ\n",
    "print(f'\\nエンコーディング前: {all_data.shape[1]}列')\n",
    "\n",
    "# ワンホットエンコーディング\n",
    "# drop_first=True: 多重共線性を防ぐために最初のカテゴリを削除\n",
    "all_data = pd.get_dummies(all_data, columns=remaining_cat_cols, drop_first=True)\n",
    "\n",
    "print(f'エンコーディング後: {all_data.shape[1]}列')\n",
    "print(f'\\n{all_data.shape[1] - len(remaining_cat_cols)}列の数値特徴量に展開されました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの型を確認（全て数値になっているか）\n",
    "non_numeric = all_data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if len(non_numeric) == 0:\n",
    "    print('全ての特徴量が数値型に変換されました')\n",
    "else:\n",
    "    print(f'警告: 以下の列がまだ数値型ではありません: {non_numeric}')\n",
    "\n",
    "print(f'\\nデータの最終形状: {all_data.shape}')\n",
    "print(f'  訓練データ: {n_train}行')\n",
    "print(f'  テストデータ: {all_data.shape[0] - n_train}行')\n",
    "print(f'  特徴量数: {all_data.shape[1]}列')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. スケーリング\n",
    "\n",
    "### なぜスケーリングが必要なのか？\n",
    "\n",
    "特徴量によってスケール（値の範囲）が大きく異なります。例えば：\n",
    "- `LotArea`（敷地面積）: 1,300 〜 200,000+\n",
    "- `OverallQual`（品質評価）: 1 〜 10\n",
    "- `HasPool`（プール有無）: 0 〜 1\n",
    "\n",
    "**線形モデル**（Ridge, Lasso, ElasticNet）は、特徴量のスケールに**敏感**です。大きなスケールの特徴量がモデルを支配し、小さなスケールの特徴量が無視される可能性があります。\n",
    "\n",
    "### StandardScalerの仕組み\n",
    "\n",
    "各特徴量について、以下の変換を行います：\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "- $\\mu$: 平均値\n",
    "- $\\sigma$: 標準偏差\n",
    "\n",
    "結果として、全ての特徴量が**平均0、標準偏差1**に標準化されます。\n",
    "\n",
    "### 注意: ツリーベースのモデルではスケーリング不要\n",
    "\n",
    "RandomForest や GradientBoosting などのツリーベースモデルは、特徴量の分割点を探すため、スケールに影響されません。ただし、今回は線形モデルも使用するため、スケーリングを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スケーリング前の値の範囲を確認（一部の特徴量）\n",
    "example_cols = ['LotArea', 'OverallQual', 'TotalSF', 'GarageArea', 'HouseAge']\n",
    "existing_cols = [c for c in example_cols if c in all_data.columns]\n",
    "\n",
    "print('スケーリング前の値の範囲:')\n",
    "for col in existing_cols:\n",
    "    print(f'  {col:15s}: min={all_data[col].min():10.1f}, max={all_data[col].max():10.1f}, '\n",
    "          f'mean={all_data[col].mean():10.1f}, std={all_data[col].std():10.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScalerの適用\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 全ての数値特徴量にスケーリングを適用\n",
    "all_data_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(all_data),\n",
    "    columns=all_data.columns,\n",
    "    index=all_data.index\n",
    ")\n",
    "\n",
    "print('StandardScalerを適用しました')\n",
    "print('\\nスケーリング後の値の範囲:')\n",
    "for col in existing_cols:\n",
    "    print(f'  {col:15s}: min={all_data_scaled[col].min():8.3f}, max={all_data_scaled[col].max():8.3f}, '\n",
    "          f'mean={all_data_scaled[col].mean():8.3f}, std={all_data_scaled[col].std():8.3f}')\n",
    "\n",
    "print('\\n全ての特徴量が平均≈0、標準偏差≈1に標準化されました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データとテストデータに再分割\n",
    "X_train = all_data_scaled.iloc[:n_train].values\n",
    "X_test = all_data_scaled.iloc[n_train:].values\n",
    "\n",
    "print(f'訓練データ: X_train={X_train.shape}, y_train={y_train.shape}')\n",
    "print(f'テストデータ: X_test={X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. ベースラインモデル（Ridge回帰）\n",
    "\n",
    "### Ridge回帰とは？\n",
    "\n",
    "Ridge回帰は、通常の線形回帰に**L2正則化**（ペナルティ項）を追加したモデルです。\n",
    "\n",
    "通常の線形回帰の損失関数：\n",
    "$$L = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "Ridge回帰の損失関数：\n",
    "$$L = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p} w_j^2$$\n",
    "\n",
    "**$\\alpha \\sum w_j^2$** がペナルティ項で、これにより：\n",
    "- 係数 $w_j$ が大きくなりすぎるのを防ぐ（**過学習を抑制**）\n",
    "- 多重共線性がある場合でも安定した推定ができる\n",
    "- $\\alpha$ は正則化の強さを制御するハイパーパラメータ\n",
    "\n",
    "### なぜRidge回帰がベースラインに適しているか？\n",
    "\n",
    "1. **解釈しやすい**: 線形モデルなので、各特徴量の影響が明確\n",
    "2. **多重共線性に強い**: 住宅データには相関の高い特徴量が多い\n",
    "3. **計算が速い**: 大量の特徴量でも素早く学習できる\n",
    "4. **ベースラインとして最適**: より複雑なモデルの性能比較の基準になる\n",
    "\n",
    "### 交差検証（Cross-Validation）とは？\n",
    "\n",
    "データを K 個の部分に分割し、各部分を順番にテストデータとして使い、残りで学習します。これにより、モデルの性能をより**信頼性高く**評価できます。\n",
    "\n",
    "1つの分割だけでは「たまたまテストデータが簡単/難しかった」可能性がありますが、K回繰り返すことで平均的な性能がわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 交差検証の設定\n",
    "# ============================================================\n",
    "\n",
    "# 5分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# RMSE を計算する関数\n",
    "def rmse_cv(model, X, y):\n",
    "    \"\"\"\n",
    "    交差検証でRMSEを計算する関数。\n",
    "    \n",
    "    sklearnのcross_val_scoreは「大きいほど良い」スコアを返すため、\n",
    "    neg_mean_squared_error（負のMSE）を使い、符号を反転してからルートを取る。\n",
    "    \"\"\"\n",
    "    scores = cross_val_score(\n",
    "        model, X, y, \n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=kf\n",
    "    )\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    return rmse_scores\n",
    "\n",
    "print('交差検証の設定:')\n",
    "print('  - 分割数: 5')\n",
    "print('  - シャッフル: あり（random_state=42）')\n",
    "print('  - 評価指標: RMSE（Root Mean Squared Error）')\n",
    "print('\\n注意: 目的変数はlog1p変換済みなので、このRMSEは実質的にRMSLE相当です')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Ridge回帰モデルの訓練と評価\n",
    "# ============================================================\n",
    "\n",
    "# Ridge回帰（alpha=10はよく使われるデフォルト値）\n",
    "ridge = Ridge(alpha=10, random_state=42)\n",
    "\n",
    "# 交差検証\n",
    "ridge_scores = rmse_cv(ridge, X_train, y_train)\n",
    "\n",
    "print('=== Ridge回帰（ベースライン）の結果 ===')\n",
    "print(f'\\n各フォールドのRMSE:')\n",
    "for i, score in enumerate(ridge_scores):\n",
    "    print(f'  Fold {i+1}: {score:.5f}')\n",
    "print(f'\\n平均RMSE: {ridge_scores.mean():.5f} (+/- {ridge_scores.std():.5f})')\n",
    "print(f'\\nこの値はlog1p(SalePrice)空間でのRMSEです')\n",
    "print(f'参考: Kaggleのリーダーボードスコア（RMSLE）と近い値になります')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. モデル比較\n",
    "\n",
    "### 各モデルの概要\n",
    "\n",
    "| モデル | 特徴 | 正則化 |\n",
    "|--------|------|--------|\n",
    "| **Ridge** | L2正則化。全ての特徴量を使い、係数を小さくする | $\\alpha \\sum w^2$ |\n",
    "| **Lasso** | L1正則化。不要な特徴量の係数を完全に0にする（特徴量選択効果） | $\\alpha \\sum |w|$ |\n",
    "| **ElasticNet** | L1とL2の組み合わせ。Lassoの特徴量選択とRidgeの安定性を両立 | $\\alpha_1 \\sum |w| + \\alpha_2 \\sum w^2$ |\n",
    "| **RandomForest** | 多数の決定木の多数決。過学習に強い。特徴量のスケールに依存しない | - |\n",
    "| **GradientBoosting** | 決定木を逐次的に追加し、前のモデルの誤差を修正していく | - |\n",
    "| **XGBoost** | GradientBoostingの高速・高精度版。正則化機能を内蔵 | - |\n",
    "\n",
    "### 線形モデル vs ツリーベースモデル\n",
    "\n",
    "- **線形モデル**（Ridge, Lasso, ElasticNet）: 特徴量と目的変数の線形関係を仮定。解釈しやすいが、非線形な関係を捉えにくい。\n",
    "- **ツリーベースモデル**（RandomForest, GradientBoosting, XGBoost）: 非線形な関係も捉えられる。一般的に予測精度が高い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 複数モデルの比較\n",
    "# ============================================================\n",
    "\n",
    "# モデルの定義\n",
    "models = {\n",
    "    'Ridge': Ridge(alpha=10, random_state=42),\n",
    "    'Lasso': Lasso(alpha=0.0005, random_state=42),\n",
    "    'ElasticNet': ElasticNet(alpha=0.0005, l1_ratio=0.5, random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(\n",
    "        n_estimators=300, max_depth=15, min_samples_split=5,\n",
    "        min_samples_leaf=2, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingRegressor(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.05,\n",
    "        min_samples_split=5, min_samples_leaf=3, random_state=42\n",
    "    ),\n",
    "}\n",
    "\n",
    "# XGBoostを試みる（インストールされていない場合はスキップ）\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    models['XGBoost'] = XGBRegressor(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=42, n_jobs=-1, verbosity=0\n",
    "    )\n",
    "    print('XGBoostが利用可能です')\n",
    "except ImportError:\n",
    "    print('XGBoostがインストールされていません。スキップします。')\n",
    "    print('インストールするには: pip install xgboost')\n",
    "\n",
    "print(f'\\n比較するモデル数: {len(models)}')\n",
    "print(f'モデル一覧: {\", \".join(models.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各モデルの交差検証を実行\n",
    "results = {}\n",
    "\n",
    "print('=== モデル比較（5分割交差検証） ===')\n",
    "print(f'{\"モデル\":<20s} {\"平均RMSE\":>10s} {\"標準偏差\":>10s} {\"最良\":>10s} {\"最悪\":>10s}')\n",
    "print('-' * 65)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = rmse_cv(model, X_train, y_train)\n",
    "    results[name] = scores\n",
    "    print(f'{name:<20s} {scores.mean():>10.5f} {scores.std():>10.5f} {scores.min():>10.5f} {scores.max():>10.5f}')\n",
    "\n",
    "# 最良モデルを特定\n",
    "best_model_name = min(results, key=lambda x: results[x].mean())\n",
    "best_rmse = results[best_model_name].mean()\n",
    "print(f'\\n最良モデル: {best_model_name} (RMSE = {best_rmse:.5f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の可視化\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "model_names = list(results.keys())\n",
    "means = [results[name].mean() for name in model_names]\n",
    "stds = [results[name].std() for name in model_names]\n",
    "\n",
    "# 最良モデルの色を変える\n",
    "colors = ['#2196F3' if name != best_model_name else '#FF5722' for name in model_names]\n",
    "\n",
    "bars = ax.bar(model_names, means, yerr=stds, capsize=5, color=colors,\n",
    "              edgecolor='black', alpha=0.8, linewidth=1.2)\n",
    "\n",
    "# 値をバーの上に表示\n",
    "for bar, mean, std in zip(bars, means, stds):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + std + 0.002,\n",
    "            f'{mean:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('RMSE (log1p空間)', fontsize=12)\n",
    "ax.set_title('モデル比較 - 5分割交差検証のRMSE\\n（低いほど良い。エラーバーは標準偏差）', fontsize=14)\n",
    "ax.set_ylim(bottom=min(means) * 0.9)\n",
    "\n",
    "# 最良モデルに注釈\n",
    "ax.annotate(f'Best: {best_model_name}', \n",
    "            xy=(model_names.index(best_model_name), min(means)),\n",
    "            xytext=(model_names.index(best_model_name), min(means) * 0.95),\n",
    "            fontsize=11, fontweight='bold', color='#FF5722',\n",
    "            ha='center')\n",
    "\n",
    "plt.xticks(rotation=15, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各モデルのフォールドごとのスコアも可視化（箱ひげ図）\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "scores_list = [results[name] for name in model_names]\n",
    "bp = ax.boxplot(scores_list, labels=model_names, patch_artist=True,\n",
    "                medianprops=dict(color='black', linewidth=2))\n",
    "\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax.set_ylabel('RMSE (log1p空間)', fontsize=12)\n",
    "ax.set_title('モデル比較 - 各フォールドのRMSE分布\\n（箱ひげ図：中央線が中央値、箱が四分位範囲）', fontsize=14)\n",
    "plt.xticks(rotation=15, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. 提出ファイル作成\n",
    "\n",
    "### 手順\n",
    "\n",
    "1. 最良モデルで全訓練データを使って再学習\n",
    "2. テストデータに対して予測\n",
    "3. 予測値に `np.expm1` を適用して元のスケールに戻す（`log1p` の逆変換）\n",
    "4. Kaggle提出形式のCSVファイルを作成\n",
    "\n",
    "### `expm1` について\n",
    "\n",
    "`np.expm1(x)` は `np.exp(x) - 1` と同じです。`log1p` の逆変換です。\n",
    "\n",
    "$$\\text{expm1}(\\text{log1p}(x)) = e^{\\ln(1+x)} - 1 = (1+x) - 1 = x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 最良モデルで予測\n",
    "# ============================================================\n",
    "\n",
    "print(f'最良モデル: {best_model_name}')\n",
    "print(f'CV RMSE: {results[best_model_name].mean():.5f}')\n",
    "\n",
    "# 最良モデルを全訓練データで再学習\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X_train, y_train)\n",
    "print(f'\\n全訓練データ（{X_train.shape[0]}サンプル）で再学習完了')\n",
    "\n",
    "# テストデータに対して予測\n",
    "y_pred_log = best_model.predict(X_test)\n",
    "\n",
    "# log1pの逆変換（expm1）で元のスケールに戻す\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "# 負の予測値がないことを確認（万が一の場合は0にクリップ）\n",
    "n_negative = (y_pred < 0).sum()\n",
    "if n_negative > 0:\n",
    "    print(f'警告: {n_negative}件の負の予測値を0に修正しました')\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "\n",
    "print(f'\\n予測値の統計:')\n",
    "print(f'  最小値: ${y_pred.min():,.0f}')\n",
    "print(f'  最大値: ${y_pred.max():,.0f}')\n",
    "print(f'  平均値: ${y_pred.mean():,.0f}')\n",
    "print(f'  中央値: ${np.median(y_pred):,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値の分布を確認\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 訓練データの実際の価格分布\n",
    "train_prices = np.expm1(y_train)\n",
    "axes[0].hist(train_prices, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('訓練データの SalePrice 分布', fontsize=13)\n",
    "axes[0].set_xlabel('SalePrice ($)')\n",
    "axes[0].set_ylabel('頻度')\n",
    "\n",
    "# テストデータの予測価格分布\n",
    "axes[1].hist(y_pred, bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('テストデータの予測 SalePrice 分布', fontsize=13)\n",
    "axes[1].set_xlabel('SalePrice ($)')\n",
    "axes[1].set_ylabel('頻度')\n",
    "\n",
    "plt.suptitle('訓練データ vs 予測値の価格分布比較', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('訓練データと予測値の分布が似ていれば、モデルは適切に学習しています')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 提出ファイルの作成\n",
    "# ============================================================\n",
    "import os\n",
    "\n",
    "# 提出用DataFrameの作成\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_id,\n",
    "    'SalePrice': y_pred\n",
    "})\n",
    "\n",
    "# 提出ディレクトリの確認・作成\n",
    "submission_dir = '/home/rex/Documents/lb/Kaggle/house-price-prediction/submissions'\n",
    "os.makedirs(submission_dir, exist_ok=True)\n",
    "\n",
    "# CSVファイルとして保存\n",
    "submission_path = os.path.join(submission_dir, 'submission_baseline.csv')\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f'提出ファイルを保存しました: {submission_path}')\n",
    "print(f'ファイルサイズ: {os.path.getsize(submission_path) / 1024:.1f} KB')\n",
    "print(f'\\n=== 提出ファイルの先頭10行 ===')\n",
    "print(submission.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル提出ファイルとの形式比較\n",
    "sample_sub = pd.read_csv('/home/rex/Documents/lb/Kaggle/house-price-prediction/data/raw/sample_submission.csv')\n",
    "\n",
    "print('=== 形式の確認 ===')\n",
    "print(f'サンプル提出:  {sample_sub.shape[0]}行, 列={list(sample_sub.columns)}')\n",
    "print(f'今回の提出:    {submission.shape[0]}行, 列={list(submission.columns)}')\n",
    "\n",
    "# IDの一致を確認\n",
    "ids_match = (sample_sub['Id'].values == submission['Id'].values).all()\n",
    "print(f'\\nIDの一致: {\"OK\" if ids_match else \"NG - 修正が必要!\"}')\n",
    "print(f'行数の一致: {\"OK\" if sample_sub.shape[0] == submission.shape[0] else \"NG - 修正が必要!\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## まとめ\n",
    "\n",
    "### 実施した前処理\n",
    "\n",
    "| ステップ | 内容 | 理由 |\n",
    "|---------|------|------|\n",
    "| 対数変換 | SalePriceにlog1p変換 | 歪んだ分布を正規化、RMSLE評価指標と整合 |\n",
    "| 外れ値除去 | GrLivArea > 4000の2件 | 異常な取引がモデルを歪める |\n",
    "| 欠損値処理 | 意味に応じたNone/0、中央値、最頻値補完 | モデルがNAを扱えないため |\n",
    "| 特徴量工学 | 総面積、築年数、バイナリフラグ等 | ドメイン知識でモデルを助ける |\n",
    "| エンコーディング | 順序→ラベル、名義→ワンホット | カテゴリを数値化（順序の有無で方法を変える） |\n",
    "| スケーリング | StandardScaler | 線形モデルのため特徴量のスケールを統一 |\n",
    "\n",
    "### 今後の改善案\n",
    "\n",
    "1. **ハイパーパラメータチューニング**: GridSearchCV や Optuna を使って最適なパラメータを探索\n",
    "2. **モデルのアンサンブル**: 複数モデルの予測を平均化（Stacking, Blending）\n",
    "3. **さらなる特徴量エンジニアリング**: 多項式特徴量、交互作用項\n",
    "4. **特徴量選択**: 重要度の低い特徴量を除去\n",
    "5. **歪度の修正**: 数値特徴量にもBox-Cox変換を適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('  前処理とベースラインモデル構築 完了！')\n",
    "print('=' * 60)\n",
    "print(f'\\n  最良モデル: {best_model_name}')\n",
    "print(f'  CV RMSE:    {results[best_model_name].mean():.5f}')\n",
    "print(f'  提出ファイル: submission_baseline.csv')\n",
    "print(f'\\n  次のステップ: ハイパーパラメータチューニングとアンサンブル')\n",
    "print('=' * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
